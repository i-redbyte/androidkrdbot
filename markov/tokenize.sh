#!/usr/bin/env bash
#
#  Преобразует произвольный .txt-файл в токенизированный формат,
#  пригодный для цепей Маркова:
#    • каждое слово, число и знак пунктуации — отдельный токен
#    • токены разделены одиночными пробелами
#    • регистр сохраняется
#  Результат записывается в  <имя_файла>_tokenized.txt  рядом с исходником.
#
#  Использование:
#      ./tokenize.sh path/to/book.txt
#

set -euo pipefail

if [[ $# -ne 1 ]]; then
  echo "Usage: $0 <input.txt>" >&2
  exit 1
fi

INPUT="$1"
[[ -f "$INPUT" ]] || { echo "File not found: $INPUT" >&2; exit 1; }

DIR=$(dirname "$INPUT")
BASE=$(basename "$INPUT")
NAME="${BASE%.*}"
OUTPUT="${DIR}/${NAME}_tokenized.txt"

# --- токенизация -----------------------------------------------------------

perl -0777 -pe '
    s/\r//g;                                # убрать CR из Windows-файлов
    s/\.{3}/ … /g;                          # многоточие как отдельный символ
    s/([[:punct:]])/ $1 /g;                 # пробелы вокруг пунктуации
    s/([0-9]+)/ $1 /g;                      # числа → отдельные токены
    s/([A-Za-z]+)/ $1 /g;                   # латиница → отдельные токены
    s/\s+/ /g;                              # схлопнуть лишние пробелы
    s/^\s+|\s+$//g;                         # обрезать края
' "$INPUT" > "$OUTPUT"

echo "Tokenized file written to: $OUTPUT"
